{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Welcome,\n",
        "This is my 2nd Neural Network Project,\n",
        "here we train a network in order to detect whether a certain MRI scan of the brain consists a tumor or not.\n",
        "\n",
        "Through this project, I've utilised three datasets from kaggle and combined them into their appropriate classes, ending up with around 5000 images to work with(which would be even greater when the image gets augmented)\n",
        "\n",
        "The model ends up with a best validation accuracy of 98.57%,showing that even with a diverse set of datasets, be it validation or training, the model works well.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ojt5yY0N8oF4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Author: Skanda Vyas"
      ],
      "metadata": {
        "id": "OboMCV8mJg55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-hx_WwupDWTb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bJiYvFQY7Jg1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "import random\n",
        "from shutil import copy2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import regularizers\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I uploaded the files to my dropbox, so we upload them from there"
      ],
      "metadata": {
        "id": "xzCEBKmy8myt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlvibgzU7V4q",
        "outputId": "a2633843-ae6a-492b-906c-93314936387d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-16 16:53:17--  https://www.dropbox.com/s/ymd7eg2mucnm4hp/kjjj.zip?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.80.18, 2620:100:6031:18::a27d:5112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.80.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/ymd7eg2mucnm4hp/kjjj.zip [following]\n",
            "--2023-06-16 16:53:17--  https://www.dropbox.com/s/raw/ymd7eg2mucnm4hp/kjjj.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc690970b41611746c2de383332b.dl.dropboxusercontent.com/cd/0/inline/B-FBrh7JPN0EQy7WlNRb85xkncmL0csxe695itDa9FqoS2fV0AB8hjCaZ5qFBHdhtk-fTTP-lUxc9JARk4Z0mObjAoink6UtBbUy1VuMMIAL5xdnUJ2v8D1fC8d5F8C9omPhZieiGXtCzs_laT45q495-0ASsERjU7YWoKoXwlkq-A/file# [following]\n",
            "--2023-06-16 16:53:18--  https://uc690970b41611746c2de383332b.dl.dropboxusercontent.com/cd/0/inline/B-FBrh7JPN0EQy7WlNRb85xkncmL0csxe695itDa9FqoS2fV0AB8hjCaZ5qFBHdhtk-fTTP-lUxc9JARk4Z0mObjAoink6UtBbUy1VuMMIAL5xdnUJ2v8D1fC8d5F8C9omPhZieiGXtCzs_laT45q495-0ASsERjU7YWoKoXwlkq-A/file\n",
            "Resolving uc690970b41611746c2de383332b.dl.dropboxusercontent.com (uc690970b41611746c2de383332b.dl.dropboxusercontent.com)... 162.125.80.15, 2620:100:6035:15::a27d:550f\n",
            "Connecting to uc690970b41611746c2de383332b.dl.dropboxusercontent.com (uc690970b41611746c2de383332b.dl.dropboxusercontent.com)|162.125.80.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/B-FhawPx2tq4YtV0o-nvuPeiNnLvigmJPt_laiXqRpgY2SH81Pi1V6-WWjXI201Hzq74WGf881O7oc-XCDkX6pX0gql7WUImiD06a2E2fI2hIdW8TN6h7Tr4WyAPFkL9n0kDhFu96QhLSCxssiFvSXAIYlSMRJ_WyYAJgGtlA9rqSxPe-X-u52y8Z6c7yONcBlMaazGEJQn-fwfPuGKwAB8w8IDs4Hic_va-pC4_eyeUxmPwyYK3qZipTX2LVxqPpGPqsqN96sVajgFIDYN9HMoFcZVL81UpZiVVreXQYU6zgyk_l1QQD0auO36qFYPSAtBQg4VDjHLbrujMfrLVJvBU4F5DBer5ZKAhnTqxD7ZNPxbxnWvYYLYLNgrgY_RTxf5TF8GqjYSByXc-YQmvvUzPPfIasFp_3fQZmTSCiEgahQ/file [following]\n",
            "--2023-06-16 16:53:19--  https://uc690970b41611746c2de383332b.dl.dropboxusercontent.com/cd/0/inline2/B-FhawPx2tq4YtV0o-nvuPeiNnLvigmJPt_laiXqRpgY2SH81Pi1V6-WWjXI201Hzq74WGf881O7oc-XCDkX6pX0gql7WUImiD06a2E2fI2hIdW8TN6h7Tr4WyAPFkL9n0kDhFu96QhLSCxssiFvSXAIYlSMRJ_WyYAJgGtlA9rqSxPe-X-u52y8Z6c7yONcBlMaazGEJQn-fwfPuGKwAB8w8IDs4Hic_va-pC4_eyeUxmPwyYK3qZipTX2LVxqPpGPqsqN96sVajgFIDYN9HMoFcZVL81UpZiVVreXQYU6zgyk_l1QQD0auO36qFYPSAtBQg4VDjHLbrujMfrLVJvBU4F5DBer5ZKAhnTqxD7ZNPxbxnWvYYLYLNgrgY_RTxf5TF8GqjYSByXc-YQmvvUzPPfIasFp_3fQZmTSCiEgahQ/file\n",
            "Reusing existing connection to uc690970b41611746c2de383332b.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15828590 (15M) [application/zip]\n",
            "Saving to: ‘Tumors.zip’\n",
            "\n",
            "Tumors.zip          100%[===================>]  15.09M  15.2MB/s    in 1.0s    \n",
            "\n",
            "2023-06-16 16:53:20 (15.2 MB/s) - ‘Tumors.zip’ saved [15828590/15828590]\n",
            "\n",
            "--2023-06-16 16:53:20--  https://www.dropbox.com/s/vchsqodcr4oid49/archive%20%285%29.zip?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.80.18, 2620:100:6031:18::a27d:5112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.80.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/vchsqodcr4oid49/archive%20%285%29.zip [following]\n",
            "--2023-06-16 16:53:20--  https://www.dropbox.com/s/raw/vchsqodcr4oid49/archive%20%285%29.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucb29afa34c988a5bf3c2469d526.dl.dropboxusercontent.com/cd/0/inline/B-GBsYhWYPdwRSZ7MWkq6L7UDtoKa3cy7aNuPb1cTvXgjR773Z07rUQfuCLAEJwEp9wGYA16ec8QHzQyPrs4-8ttlfK1ru0KT-1fCmuaSnqYe6o5S-2Ye4o4hY_QRx1ta_O4-OdDun5g72-zt4THSBxzaYF0VrK7UoWLXxL6XF307A/file# [following]\n",
            "--2023-06-16 16:53:21--  https://ucb29afa34c988a5bf3c2469d526.dl.dropboxusercontent.com/cd/0/inline/B-GBsYhWYPdwRSZ7MWkq6L7UDtoKa3cy7aNuPb1cTvXgjR773Z07rUQfuCLAEJwEp9wGYA16ec8QHzQyPrs4-8ttlfK1ru0KT-1fCmuaSnqYe6o5S-2Ye4o4hY_QRx1ta_O4-OdDun5g72-zt4THSBxzaYF0VrK7UoWLXxL6XF307A/file\n",
            "Resolving ucb29afa34c988a5bf3c2469d526.dl.dropboxusercontent.com (ucb29afa34c988a5bf3c2469d526.dl.dropboxusercontent.com)... 162.125.80.15, 2620:100:6031:15::a27d:510f\n",
            "Connecting to ucb29afa34c988a5bf3c2469d526.dl.dropboxusercontent.com (ucb29afa34c988a5bf3c2469d526.dl.dropboxusercontent.com)|162.125.80.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/B-FDOiYL4PYnFVyHTX5OSuC5mJFsnwgALHnikg54jAdkaVtifpCG7lproUtoLNb3pw-c6ZWUlVrbVq6y2Yjwp-AKLr5_osL214KLvVANQFSVVMGzwySXjUIiZg7ktUKkXdM0RURmeMaqHLHHGebef9mwS6bIb_ALVYWRXjI6KqBBVBvNL7r5O8Xbme2uIcpjxouHNtPjzhA-HxgEW7NRTL5Ek6EO7o9QIs6jKafZYsez0TLPIGZ6OnJblwwAH25BdCrQ8uLhYo6ebqAt4K5QAOyL2QqTzLnAgCfTU-40VIG2OR69i-6eZ6tSBYJrnhkXvT5UX73rzv8FIvoCMvFOKVwxGnM3hTVxgxz_XFS4gmDp1Hp2HSffXTUXpnNyFDgA-CEZaz3Q9z-zYrN9fKjSvmug_2eoIs3zDnudfe9IvxbYFA/file [following]\n",
            "--2023-06-16 16:53:22--  https://ucb29afa34c988a5bf3c2469d526.dl.dropboxusercontent.com/cd/0/inline2/B-FDOiYL4PYnFVyHTX5OSuC5mJFsnwgALHnikg54jAdkaVtifpCG7lproUtoLNb3pw-c6ZWUlVrbVq6y2Yjwp-AKLr5_osL214KLvVANQFSVVMGzwySXjUIiZg7ktUKkXdM0RURmeMaqHLHHGebef9mwS6bIb_ALVYWRXjI6KqBBVBvNL7r5O8Xbme2uIcpjxouHNtPjzhA-HxgEW7NRTL5Ek6EO7o9QIs6jKafZYsez0TLPIGZ6OnJblwwAH25BdCrQ8uLhYo6ebqAt4K5QAOyL2QqTzLnAgCfTU-40VIG2OR69i-6eZ6tSBYJrnhkXvT5UX73rzv8FIvoCMvFOKVwxGnM3hTVxgxz_XFS4gmDp1Hp2HSffXTUXpnNyFDgA-CEZaz3Q9z-zYrN9fKjSvmug_2eoIs3zDnudfe9IvxbYFA/file\n",
            "Reusing existing connection to ucb29afa34c988a5bf3c2469d526.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 67374128 (64M) [application/zip]\n",
            "Saving to: ‘Tumors2.zip’\n",
            "\n",
            "Tumors2.zip         100%[===================>]  64.25M  24.9MB/s    in 2.6s    \n",
            "\n",
            "2023-06-16 16:53:25 (24.9 MB/s) - ‘Tumors2.zip’ saved [67374128/67374128]\n",
            "\n",
            "--2023-06-16 16:53:25--  https://www.dropbox.com/s/d327vnslutc6c6z/archive%20%286%29.zip?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.80.18, 2620:100:6031:18::a27d:5112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.80.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/d327vnslutc6c6z/archive%20%286%29.zip [following]\n",
            "--2023-06-16 16:53:25--  https://www.dropbox.com/s/raw/d327vnslutc6c6z/archive%20%286%29.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc1b117f592534730fdd8e4fb63a.dl.dropboxusercontent.com/cd/0/inline/B-FkOq8sFv6uyl7J3EYYliMXkxs8EEu9bTsTvDMSVK-x8-KTUuE7OcpJUdM6B7rJOW8rT18eAeYkC3yzKv9fr-xE9iYRfV_H4HdmKIUtqYFFAD1MWem-Nt6VD2yQPTz8xtTHmH0V1L4B0RLGMgvbe6jhGW4DrXDVisaXr4lrb4QrIw/file# [following]\n",
            "--2023-06-16 16:53:26--  https://uc1b117f592534730fdd8e4fb63a.dl.dropboxusercontent.com/cd/0/inline/B-FkOq8sFv6uyl7J3EYYliMXkxs8EEu9bTsTvDMSVK-x8-KTUuE7OcpJUdM6B7rJOW8rT18eAeYkC3yzKv9fr-xE9iYRfV_H4HdmKIUtqYFFAD1MWem-Nt6VD2yQPTz8xtTHmH0V1L4B0RLGMgvbe6jhGW4DrXDVisaXr4lrb4QrIw/file\n",
            "Resolving uc1b117f592534730fdd8e4fb63a.dl.dropboxusercontent.com (uc1b117f592534730fdd8e4fb63a.dl.dropboxusercontent.com)... 162.125.80.15, 2620:100:6035:15::a27d:550f\n",
            "Connecting to uc1b117f592534730fdd8e4fb63a.dl.dropboxusercontent.com (uc1b117f592534730fdd8e4fb63a.dl.dropboxusercontent.com)|162.125.80.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/B-Ecd2WyUMAfBDi0K1MDxJ_-dAyhAENRnNZo-8r6XQteEckDHN2RAb-JHjn1FyV-aJFx9NzjjstGFPSTcGVCnrRRqk9Uuw-utx8Y0wTbuP10QJmPYGWw_YUv8rRiChpdjC1O0FHufaSo-1ao868pKM4_6mnsMrqdfflCKNR6pQeS8hl8IkOgHRLIrY4iOtypYm2-By0QVxxzs4N9gV10iYa7eFhRAdtOIXV09v_s4aW6UBJBg2oMnOdBSPA8KW2XMXh5GUAOY_6Dk6-1Fo6DjC9mc28TJyRvjeEjKkyTxGHj_AkYHFFJX170ZEKGKTkeL5V0izu4wCF6xGcfzT71pA98mGBWJJ_JmrMP2Hi8zUgaCskqhCFnElVo5HIm3lzHJGy5P7OoheMSeI3OVBzIfxIwgf1yJSs9DCfBfKokZlKZrQ/file [following]\n",
            "--2023-06-16 16:53:26--  https://uc1b117f592534730fdd8e4fb63a.dl.dropboxusercontent.com/cd/0/inline2/B-Ecd2WyUMAfBDi0K1MDxJ_-dAyhAENRnNZo-8r6XQteEckDHN2RAb-JHjn1FyV-aJFx9NzjjstGFPSTcGVCnrRRqk9Uuw-utx8Y0wTbuP10QJmPYGWw_YUv8rRiChpdjC1O0FHufaSo-1ao868pKM4_6mnsMrqdfflCKNR6pQeS8hl8IkOgHRLIrY4iOtypYm2-By0QVxxzs4N9gV10iYa7eFhRAdtOIXV09v_s4aW6UBJBg2oMnOdBSPA8KW2XMXh5GUAOY_6Dk6-1Fo6DjC9mc28TJyRvjeEjKkyTxGHj_AkYHFFJX170ZEKGKTkeL5V0izu4wCF6xGcfzT71pA98mGBWJJ_JmrMP2Hi8zUgaCskqhCFnElVo5HIm3lzHJGy5P7OoheMSeI3OVBzIfxIwgf1yJSs9DCfBfKokZlKZrQ/file\n",
            "Reusing existing connection to uc1b117f592534730fdd8e4fb63a.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 88097875 (84M) [application/zip]\n",
            "Saving to: ‘Tumors3.zip’\n",
            "\n",
            "Tumors3.zip         100%[===================>]  84.02M  25.8MB/s    in 3.3s    \n",
            "\n",
            "2023-06-16 16:53:30 (25.8 MB/s) - ‘Tumors3.zip’ saved [88097875/88097875]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O Tumors.zip https://www.dropbox.com/s/ymd7eg2mucnm4hp/kjjj.zip?dl=0\n",
        "!wget -O Tumors2.zip https://www.dropbox.com/s/vchsqodcr4oid49/archive%20%285%29.zip?dl=0\n",
        "!wget -O Tumors3.zip https://www.dropbox.com/s/d327vnslutc6c6z/archive%20%286%29.zip?dl=0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The files are installed as .zip , so we use the zipfile package in order to extract all the files into a new folder."
      ],
      "metadata": {
        "id": "p0zcgzfVDXfD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pTc2fUZ7Nwpu"
      },
      "outputs": [],
      "source": [
        "zip_ref = \"/content/Tumors.zip\"\n",
        "ext = zipfile.ZipFile(zip_ref,'r')\n",
        "ext.extractall(\"Project\")\n",
        "ext.close()\n",
        "\n",
        "zip_ref2 = \"/content/Tumors2.zip\"\n",
        "ext = zipfile.ZipFile(zip_ref2,'r')\n",
        "ext.extractall(\"Project\")\n",
        "ext.close()\n",
        "\n",
        "zip_ref3 = \"/content/Tumors3.zip\"\n",
        "ext = zipfile.ZipFile(zip_ref3,'r')\n",
        "ext.extractall(\"Project\")\n",
        "ext.close()\n",
        "\n",
        "\n",
        "shutil.rmtree(\"/content/Project/brain_tumor_dataset\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A method used to create directories in order to store the images present in the datasets."
      ],
      "metadata": {
        "id": "Gc3VvPL0DiTi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DxVuA3taQjnH"
      },
      "outputs": [],
      "source": [
        "def create_directories(dir):\n",
        "   tr = os.path.join(dir,\"training\")\n",
        "   os.makedirs(tr,exist_ok=True)\n",
        "   va = os.path.join(dir,\"validation\")\n",
        "   os.makedirs(va,exist_ok=True)\n",
        "   b = [\"yes\",\"no\"]\n",
        "   for a in b:\n",
        "    os.makedirs(os.path.join(tr,a),exist_ok=True)\n",
        "    os.makedirs(os.path.join(va,a),exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another method which splits the data from a given directory, into two other directories in a ratio of 4:1.\n",
        "\n",
        "The method is used to split a bunch of images, such that some of them are copied to the training directory, and the rest of them are copied to the validation directory."
      ],
      "metadata": {
        "id": "1MKiSOeDDso4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "By7BH-YfRd_H"
      },
      "outputs": [],
      "source": [
        "def split_data(SOURCE_DIR,TRAINING_DIR,VALIDATION_DIR):\n",
        "    k = os.listdir(SOURCE_DIR)\n",
        "    a = random.sample(k,len(k))\n",
        "    count = 0\n",
        "    #the 0.8, shows that 80% of the data goes to the trianing directory\n",
        "    limit = len(a) * 0.8\n",
        "    for image in a:\n",
        "      if(count<=limit):\n",
        "        copy2(os.path.join(SOURCE_DIR,image),TRAINING_DIR)\n",
        "        count+=1\n",
        "      else:\n",
        "        copy2(os.path.join(SOURCE_DIR,image),VALIDATION_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "68a4hdvhVr2M"
      },
      "outputs": [],
      "source": [
        "create_directories(\"/content/\")\n",
        "split_data(\"/content/Project/yes\",\"/content/training/yes\",\"/content/validation/yes\")\n",
        "split_data(\"/content/Project/no\",\"/content/training/no\",\"/content/validation/no\")\n",
        "split_data(\"/content/Project/Brain_Tumor_Detection/yes\",\"/content/training/yes\",\"/content/validation/yes\")\n",
        "split_data(\"/content/Project/Brain_Tumor_Detection/no\",\"/content/training/no\",\"/content/validation/no\")\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, I use ImageDataGenerator in order to augment the images in order to train the model more effectively.\n",
        "\n",
        "We also use flow_from_directory to resize the images to a particular size and provide images for the model"
      ],
      "metadata": {
        "id": "yncTrUQWEnkk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAMIgBZ5hSIx",
        "outputId": "dd0640fc-5e6a-44ce-d8ff-5b572977825e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3091 images belonging to 2 classes.\n",
            "Found 1139 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   rotation_range = 10,\n",
        "                                   height_shift_range = 0.1,\n",
        "                                   width_shift_range = 0.1,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True,\n",
        "                                   brightness_range = (0.8,1.2),\n",
        "                                   fill_mode = 'nearest'\n",
        "                                   )\n",
        "\n",
        "train_gen =train_datagen.flow_from_directory(\"/content/training\",target_size=(200,200),class_mode='binary',batch_size = 16)\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_gen = validation_datagen.flow_from_directory(\"/content/validation\",target_size=(200,200),class_mode='binary',batch_size = 16)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the model used.\n",
        "\n",
        "There are 4 Convolutional Layers(with L2 regularizers), followed by Pooling layers. This is followed by a flatten layer, followed by 3 Dense layers.\n",
        "\n",
        "As there are only two outputs i.e. yes or no, we use 1 neuron in the last layer with a sigmoid activation."
      ],
      "metadata": {
        "id": "IG0v6xOXE78h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "unEPpBmMjrh3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32,(3,3),activation='relu',input_shape =(200,200,3),kernel_regularizer=regularizers.l2(0.01)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64,(3,3),activation='relu',kernel_regularizer=regularizers.l2(0.01)),\n",
        "    tf.keras.layers.BatchNormalization(axis=-1),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64,(3,3),activation='relu',kernel_regularizer=regularizers.l2(0.01)),\n",
        "    tf.keras.layers.BatchNormalization(axis=-1),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64,(3,3),activation='relu',kernel_regularizer=regularizers.l2(0.01)),\n",
        "    tf.keras.layers.BatchNormalization(axis=-1),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1024,activation='relu'),\n",
        "    tf.keras.layers.Dense(512,activation='relu'),\n",
        "    tf.keras.layers.Dense(1,activation = 'sigmoid') ])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we compile it with the adam optimizer, and use the binary crossentropy loss function.\n",
        "\n",
        "We train the model for a 100 epochs, and in batch sizes of 16."
      ],
      "metadata": {
        "id": "Cx2xxqyoFmDV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2uInAjrkXVk",
        "outputId": "1ee17413-446a-413d-be50-d8bf1812c7e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "194/194 [==============================] - 67s 260ms/step - loss: 2.0373 - accuracy: 0.6891 - val_loss: 1.9188 - val_accuracy: 0.4759\n",
            "Epoch 2/100\n",
            "194/194 [==============================] - 45s 231ms/step - loss: 1.1417 - accuracy: 0.7263 - val_loss: 0.9789 - val_accuracy: 0.7094\n",
            "Epoch 3/100\n",
            "194/194 [==============================] - 53s 276ms/step - loss: 0.7993 - accuracy: 0.7713 - val_loss: 1.2038 - val_accuracy: 0.5628\n",
            "Epoch 4/100\n",
            "194/194 [==============================] - 51s 262ms/step - loss: 0.6644 - accuracy: 0.7823 - val_loss: 2.4082 - val_accuracy: 0.4960\n",
            "Epoch 5/100\n",
            "194/194 [==============================] - 54s 276ms/step - loss: 0.5554 - accuracy: 0.8140 - val_loss: 0.6737 - val_accuracy: 0.7972\n",
            "Epoch 6/100\n",
            "194/194 [==============================] - 45s 233ms/step - loss: 0.5128 - accuracy: 0.8198 - val_loss: 0.4317 - val_accuracy: 0.8709\n",
            "Epoch 7/100\n",
            "194/194 [==============================] - 46s 240ms/step - loss: 0.4863 - accuracy: 0.8285 - val_loss: 2.0639 - val_accuracy: 0.4996\n",
            "Epoch 8/100\n",
            "194/194 [==============================] - 51s 261ms/step - loss: 0.4528 - accuracy: 0.8522 - val_loss: 0.5139 - val_accuracy: 0.8156\n",
            "Epoch 9/100\n",
            "194/194 [==============================] - 48s 245ms/step - loss: 0.4296 - accuracy: 0.8625 - val_loss: 2.1110 - val_accuracy: 0.6260\n",
            "Epoch 10/100\n",
            "194/194 [==============================] - 46s 234ms/step - loss: 0.4324 - accuracy: 0.8628 - val_loss: 0.3970 - val_accuracy: 0.8665\n",
            "Epoch 11/100\n",
            "194/194 [==============================] - 46s 236ms/step - loss: 0.4099 - accuracy: 0.8677 - val_loss: 0.4588 - val_accuracy: 0.8358\n",
            "Epoch 12/100\n",
            "194/194 [==============================] - 47s 242ms/step - loss: 0.3811 - accuracy: 0.8858 - val_loss: 0.5820 - val_accuracy: 0.7796\n",
            "Epoch 13/100\n",
            "194/194 [==============================] - 45s 234ms/step - loss: 0.3648 - accuracy: 0.8962 - val_loss: 0.2747 - val_accuracy: 0.9429\n",
            "Epoch 14/100\n",
            "194/194 [==============================] - 48s 248ms/step - loss: 0.3442 - accuracy: 0.9049 - val_loss: 0.7688 - val_accuracy: 0.7243\n",
            "Epoch 15/100\n",
            "194/194 [==============================] - 46s 239ms/step - loss: 0.3904 - accuracy: 0.8877 - val_loss: 0.3117 - val_accuracy: 0.9280\n",
            "Epoch 16/100\n",
            "194/194 [==============================] - 45s 233ms/step - loss: 0.3327 - accuracy: 0.9178 - val_loss: 0.5876 - val_accuracy: 0.8183\n",
            "Epoch 17/100\n",
            "194/194 [==============================] - 46s 239ms/step - loss: 0.3547 - accuracy: 0.9013 - val_loss: 1.6492 - val_accuracy: 0.7120\n",
            "Epoch 18/100\n",
            "194/194 [==============================] - 46s 238ms/step - loss: 0.3277 - accuracy: 0.9114 - val_loss: 0.6132 - val_accuracy: 0.7919\n",
            "Epoch 19/100\n",
            "189/194 [============================>.] - ETA: 1s - loss: 0.3323 - accuracy: 0.9193"
          ]
        }
      ],
      "source": [
        "model.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics = [\"accuracy\"])\n",
        "\n",
        "model.fit(train_gen, epochs = 100,validation_data=validation_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, you can upload images of MRI scans of the brain, through which the model predicts whether the images show a presence of a tumor or not."
      ],
      "metadata": {
        "id": "H5AIq3blIyih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = load_img(path, target_size=(300, 300))\n",
        "  x = img_to_array(img)\n",
        "  x /= 255\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  print(classes[0])\n",
        "\n",
        "  if classes[0]>0.5:\n",
        "    print(fn + \" does not have a tumor present\")\n",
        "  else:\n",
        "    print(fn + \" has a tumor present\")"
      ],
      "metadata": {
        "id": "RlpTu-524Z4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XVXkeVp-JH-v"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}