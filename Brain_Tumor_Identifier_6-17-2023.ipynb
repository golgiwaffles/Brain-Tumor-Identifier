{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Welcome,\n",
        "This is my 2nd Neural Network Project,\n",
        "here we train a network in order to detect whether a certain MRI scan of the brain consists a tumor or not.\n",
        "\n",
        "Through this project, I've utilised three datasets from kaggle and combined them into their appropriate classes, ending up with around 5000 images to work with(which would be even greater when the image gets augmented)\n",
        "\n",
        "The model ends up with a best validation accuracy of 98.57%,showing that even with a diverse set of datasets, be it validation or training, the model works well.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ojt5yY0N8oF4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Author: Skanda Vyas"
      ],
      "metadata": {
        "id": "OboMCV8mJg55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-hx_WwupDWTb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJiYvFQY7Jg1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "import random\n",
        "from shutil import copy2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import regularizers\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I uploaded the files to my dropbox, so we upload them from there"
      ],
      "metadata": {
        "id": "xzCEBKmy8myt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlvibgzU7V4q"
      },
      "outputs": [],
      "source": [
        "!wget -O Tumors.zip https://www.dropbox.com/s/ymd7eg2mucnm4hp/kjjj.zip?dl=0\n",
        "!wget -O Tumors2.zip https://www.dropbox.com/s/vchsqodcr4oid49/archive%20%285%29.zip?dl=0\n",
        "!wget -O Tumors3.zip https://www.dropbox.com/s/d327vnslutc6c6z/archive%20%286%29.zip?dl=0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The files are installed as .zip , so we use the zipfile package in order to extract all the files into a new folder."
      ],
      "metadata": {
        "id": "p0zcgzfVDXfD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTc2fUZ7Nwpu"
      },
      "outputs": [],
      "source": [
        "zip_ref = \"/content/Tumors.zip\"\n",
        "ext = zipfile.ZipFile(zip_ref,'r')\n",
        "ext.extractall(\"Project\")\n",
        "ext.close()\n",
        "\n",
        "zip_ref2 = \"/content/Tumors2.zip\"\n",
        "ext = zipfile.ZipFile(zip_ref2,'r')\n",
        "ext.extractall(\"Project\")\n",
        "ext.close()\n",
        "\n",
        "zip_ref3 = \"/content/Tumors3.zip\"\n",
        "ext = zipfile.ZipFile(zip_ref3,'r')\n",
        "ext.extractall(\"Project\")\n",
        "ext.close()\n",
        "\n",
        "\n",
        "shutil.rmtree(\"/content/Project/brain_tumor_dataset\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A method used to create directories in order to store the images present in the datasets."
      ],
      "metadata": {
        "id": "Gc3VvPL0DiTi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxVuA3taQjnH"
      },
      "outputs": [],
      "source": [
        "def create_directories(dir):\n",
        "   tr = os.path.join(dir,\"training\")\n",
        "   os.makedirs(tr,exist_ok=True)\n",
        "   va = os.path.join(dir,\"validation\")\n",
        "   os.makedirs(va,exist_ok=True)\n",
        "   b = [\"yes\",\"no\"]\n",
        "   for a in b:\n",
        "    os.makedirs(os.path.join(tr,a),exist_ok=True)\n",
        "    os.makedirs(os.path.join(va,a),exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another method which splits the data from a given directory, into two other directories in a ratio of 4:1.\n",
        "\n",
        "The method is used to split a bunch of images, such that some of them are copied to the training directory, and the rest of them are copied to the validation directory."
      ],
      "metadata": {
        "id": "1MKiSOeDDso4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "By7BH-YfRd_H"
      },
      "outputs": [],
      "source": [
        "def split_data(SOURCE_DIR,TRAINING_DIR,VALIDATION_DIR):\n",
        "    k = os.listdir(SOURCE_DIR)\n",
        "    a = random.sample(k,len(k))\n",
        "    count = 0\n",
        "    #the 0.8, shows that 80% of the data goes to the trianing directory\n",
        "    limit = len(a) * 0.8\n",
        "    for image in a:\n",
        "      if(count<=limit):\n",
        "        copy2(os.path.join(SOURCE_DIR,image),TRAINING_DIR)\n",
        "        count+=1\n",
        "      else:\n",
        "        copy2(os.path.join(SOURCE_DIR,image),VALIDATION_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68a4hdvhVr2M"
      },
      "outputs": [],
      "source": [
        "create_directories(\"/content/\")\n",
        "split_data(\"/content/Project/yes\",\"/content/training/yes\",\"/content/validation/yes\")\n",
        "split_data(\"/content/Project/no\",\"/content/training/no\",\"/content/validation/no\")\n",
        "split_data(\"/content/Project/Brain_Tumor_Detection/yes\",\"/content/training/yes\",\"/content/validation/yes\")\n",
        "split_data(\"/content/Project/Brain_Tumor_Detection/no\",\"/content/training/no\",\"/content/validation/no\")\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, I use ImageDataGenerator in order to augment the images in order to train the model more effectively.\n",
        "\n",
        "We also use flow_from_directory to resize the images to a particular size and provide images for the model"
      ],
      "metadata": {
        "id": "yncTrUQWEnkk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAMIgBZ5hSIx",
        "outputId": "dd0640fc-5e6a-44ce-d8ff-5b572977825e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3091 images belonging to 2 classes.\n",
            "Found 1139 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   rotation_range = 10,\n",
        "                                   height_shift_range = 0.1,\n",
        "                                   width_shift_range = 0.1,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True,\n",
        "                                   brightness_range = (0.8,1.2),\n",
        "                                   fill_mode = 'nearest'\n",
        "                                   )\n",
        "\n",
        "train_gen =train_datagen.flow_from_directory(\"/content/training\",target_size=(200,200),class_mode='binary',batch_size = 16)\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_gen = validation_datagen.flow_from_directory(\"/content/validation\",target_size=(200,200),class_mode='binary',batch_size = 16)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the model used.\n",
        "\n",
        "There are 4 Convolutional Layers(with L2 regularizers), followed by Pooling layers. This is followed by a flatten layer, followed by 3 Dense layers.\n",
        "\n",
        "As there are only two outputs i.e. yes or no, we use 1 neuron in the last layer with a sigmoid activation."
      ],
      "metadata": {
        "id": "IG0v6xOXE78h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unEPpBmMjrh3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32,(3,3),activation='relu',input_shape =(200,200,3),kernel_regularizer=regularizers.l2(0.01)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64,(3,3),activation='relu',kernel_regularizer=regularizers.l2(0.01)),\n",
        "    tf.keras.layers.BatchNormalization(axis=-1),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64,(3,3),activation='relu',kernel_regularizer=regularizers.l2(0.01)),\n",
        "    tf.keras.layers.BatchNormalization(axis=-1),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64,(3,3),activation='relu',kernel_regularizer=regularizers.l2(0.01)),\n",
        "    tf.keras.layers.BatchNormalization(axis=-1),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1024,activation='relu'),\n",
        "    tf.keras.layers.Dense(512,activation='relu'),\n",
        "    tf.keras.layers.Dense(1,activation = 'sigmoid') ])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we compile it with the adam optimizer, and use the binary crossentropy loss function.\n",
        "\n",
        "We train the model for a 100 epochs, and in batch sizes of 16."
      ],
      "metadata": {
        "id": "Cx2xxqyoFmDV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2uInAjrkXVk"
      },
      "outputs": [],
      "source": [
        "model.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics = [\"accuracy\"])\n",
        "\n",
        "model.fit(train_gen, epochs = 100,validation_data=validation_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, you can upload images of MRI scans of the brain, through which the model predicts whether the images show a presence of a tumor or not."
      ],
      "metadata": {
        "id": "H5AIq3blIyih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = load_img(path, target_size=(300, 300))\n",
        "  x = img_to_array(img)\n",
        "  x /= 255\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  print(classes[0])\n",
        "\n",
        "  if classes[0]>0.5:\n",
        "    print(fn + \" does not have a tumor present\")\n",
        "  else:\n",
        "    print(fn + \" has a tumor present\")"
      ],
      "metadata": {
        "id": "RlpTu-524Z4n"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}